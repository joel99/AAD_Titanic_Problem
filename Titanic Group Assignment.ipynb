{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors:\n",
    "    Aaron McDaniel,\n",
    "    Jeffrey Minowa,\n",
    "    Joshua Reno,\n",
    "    & Joel Ye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import all of the libraries and files we are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import parser\n",
    "import svm\n",
    "import rfClassifier\n",
    "import knnClassifier\n",
    "import gnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need methods to import the data into a usable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    url = 'data/' + filename\n",
    "    df = pd.read_csv(url, sep=',')\n",
    "    print(\"Loaded \" + filename)\n",
    "    return df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method will read in a csv file in the data folder and convert it into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "train_fn = 'train.csv'\n",
    "test_fn = 'test.csv'\n",
    "test_label_fn = 'gender_submission.csv'\n",
    "folds = 5\n",
    "\n",
    "def load_split_all():\n",
    "    le = LabelEncoder()\n",
    "    train_data = load_data(train_fn)\n",
    "    test_data = load_data(test_fn)\n",
    "    test_labels = load_data(test_label_fn)\n",
    "\n",
    "    # Note test data has different data order\n",
    "    # Convert sex column (col 4)\n",
    "    le.fit([\"male\", \"female\"])\n",
    "    train_data[:, 4] = le.transform(train_data[:, 4])\n",
    "    test_data[:, 3] = le.transform(test_data[:, 3])\n",
    "\n",
    "    # Convert embark column (col 11)\n",
    "    # le.fit([\"S\", \"C\", \"Q\", None])\n",
    "    # print(train_data[:, 11])\n",
    "    # train_data[:, 11] = le.transform(train_data[:, 11])\n",
    "    # test_data[:, 10] = le.transform(test_data[:, 10])\n",
    "    \n",
    "    # Feature selection:\n",
    "    # Trim passenger_id (c0), name (c3), ticket number (c8), cabin number (c10)\n",
    "    # As we're unsure about cabin_number domain effect, we're just dropping it\n",
    "    # Dropping embark since we think it's not too helpful, and has NaN\n",
    "    train_data = np.delete(train_data, [0, 3, 8, 10, 11], axis = 1)\n",
    "    test_data = np.delete(test_data, [0, 2, 7, 9, 10], axis = 1)\n",
    "\n",
    "    # Fill in NaN\n",
    "    train_data = np.where(pd.isnull(train_data), -1, train_data)\n",
    "    # test_data = np.where(pd.isnull(test_data), -1, test_data)\n",
    "    x_test = np.where(pd.isnull(test_data), -1, test_data)\n",
    "    y_test = test_labels\n",
    "\n",
    "    # Separate train_data into x and y\n",
    "    x_train = train_data[:, 1:].astype('float')\n",
    "    y_train = train_data[:, 0].astype('int')\n",
    "    return ((x_train, y_train), (x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method takes in all relevent files and creates train and test datasets that are further split up into data and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need methods that can evaluate and rank classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(clf, data, labels):\n",
    "    \"\"\"\n",
    "    calculates the precision and recall for the given classifier on the given set of data and labels\n",
    "\n",
    "    :param clf: untrained classifier to be evaluated\n",
    "    :param data: the dataset used for cross validation\n",
    "    :param labels: the correct labels that match with the given data\n",
    "    :return: a tuple of the precision and recall scores for the given classifier\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits = 3, shuffle=False, random_state=0)\n",
    "    precision = cross_val_score(clf, data, labels, scoring='precision', cv=kf, n_jobs=-1)\n",
    "    recall = cross_val_score(clf, data, labels, scoring='recall', cv=kf, n_jobs=-1)\n",
    "    precision = precision.mean()\n",
    "    recall = recall.mean()\n",
    "\n",
    "    return (precision, recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method above will return the average precision and recall\n",
    "of the inputted classifier obtained during 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_FP_FN(labels, precision, recall):\n",
    "    \"\"\"\n",
    "    converts form precision and recall to FP and FN.\n",
    "    Since Recall = TP/(TP + FN), TP = Recall * Positives\n",
    "    This means we can solve for FN & FP with\n",
    "    FN = TP/Recall - TP\n",
    "    FP = TP/Precision - TP\n",
    "\n",
    "    :param labels: the list of numeric labels that the precision and recall metrics came from\n",
    "    :param precision: the precision of some classifier on the given labels\n",
    "    :param recall: the recall of some classifier on the given labels\n",
    "    :return: a tuple containing FP and FN in that order\n",
    "    \"\"\"\n",
    "    positives = sum([1 for l in labels if l == 1])\n",
    "    tp = int(recall * positives)\n",
    "    fn = int(tp / recall) - tp\n",
    "    fp = int(tp / precision) - tp\n",
    "\n",
    "    return (fp, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since score returns precision and recall, the above method converts\n",
    "those metrics to False positives and false negatives with added\n",
    "information from the dataset labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pareto_dominance_min(ind1, ind2):\n",
    "    \"\"\"\n",
    "    returns true if ind1 dominates ind2 by the metrics that should be minimized\n",
    "\n",
    "    :param ind1: tuple of FP and FN\n",
    "    :param ind2: tuple of FP and FN\n",
    "    :return: boolean representing if ind1 dominates ind2 using the metrics that should be minimized\n",
    "    \"\"\"\n",
    "\n",
    "    not_equal = False\n",
    "    for value_1, value_2 in zip(ind1, ind2):\n",
    "        if value_1 > value_2:\n",
    "            return False\n",
    "        elif value_1 < value_2:\n",
    "            not_equal = True\n",
    "    return not_equal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method above will return a boolean representation of if ind1 \n",
    "is pareto dominant compared to ind2 assuming that the 2 scores \n",
    "assiciated with each individual should be minimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_front(front, ind, comp):\n",
    "    \"\"\"\n",
    "    Makes a new pareto front out of the old pareto front and new individual\n",
    "    In this context an individual consists of scores and their hyper parameters\n",
    "    For example ind[0] is a tuple of precision and recall scores\n",
    "    and ind[1] is a list of the hyper-parameters needed to recreate the classifier\n",
    "\n",
    "    :param front: the old pareto front to be updated\n",
    "    :param ind: the new individual that may or may not change the old pareto front\n",
    "    :param comp: the method used to compare individuals as being pareto dominant or not\n",
    "    :return: the new pareto front\n",
    "    \"\"\"\n",
    "    # A member belongs on the front if it dominates or is not dominated by new ind\n",
    "    # New ind belongs on front if it is not dominated by any\n",
    "    # If new ind dominated, rest of front won't be dominated\n",
    "    newFront = []\n",
    "    isNewDominated = False\n",
    "    for i in range(len(front)):\n",
    "        old = front[i]\n",
    "        if comp(old[0], ind[0]): # Careful to compare the scores\n",
    "            isNewDominated = True\n",
    "            break\n",
    "        if not comp(ind[0], old[0]):\n",
    "            newFront.append(old)\n",
    "    if isNewDominated:\n",
    "        newFront.extend(front[i:]) # add rest of old front\n",
    "    else:\n",
    "        newFront.append(ind)\n",
    "    return newFront"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above method will return the pareto front consisting of the \n",
    "old pareto front and one new individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_rf(data, labels):\n",
    "    # RF Hyperparams\n",
    "    n_trees = range(5, 20)\n",
    "    max_depth = range(3, 7)\n",
    "\n",
    "    front = []\n",
    "    hyperparams = (n_trees, max_depth)\n",
    "    for h1 in hyperparams[0]:\n",
    "        for h2 in hyperparams[1]:\n",
    "            clf = RandomForestClassifier(n_estimators=h1, max_depth=h2)\n",
    "            score = score(clf, data, labels)\n",
    "            score = convert_to_FP_FN(labels, score[0], score[1])\n",
    "\n",
    "            ind = [score, (h1, h2)]\n",
    "            front = update_front(front, ind, pareto_dominance_min)\n",
    "\n",
    "            # Document performance\n",
    "            # print(\"Params\\nn_trees: %d\\tmax_depth: %d\" % (h1, h2))\n",
    "            # print(\"Precision: %f\\tRecall: %f\" % (score[0], score[1]))\n",
    "            # print(\"*********************************************\")\n",
    "    return front\n",
    "    # return generate_RF_front(front)\n",
    "\n",
    "def generate_RF_front(front):\n",
    "    # implements svms for each point on the pareto front\n",
    "    # returns a list of SVMs\n",
    "    models = []\n",
    "    for ind in front:\n",
    "        clf = RandomForestClassifier(n_estimators=ind[1][0], max_depth=ind[1][1])\n",
    "        models += [clf]\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above methods will find an optimal pareto front for the random forrest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_SVM(data, labels):\n",
    "    clf = svm.SVC()\n",
    "\n",
    "    kernels = ['rbf']\n",
    "    probabilities = [False, True]\n",
    "    tols = [0.00001, 0.0001, 0.001, 0.01]\n",
    "    \n",
    "    front = []  # list of best scores & params\n",
    "\n",
    "    print(\"starting svm search\")\n",
    "\n",
    "    # block searching for best parameters based on cross validation\n",
    "    for k in kernels:\n",
    "        for p in probabilities:\n",
    "            for t in tols:\n",
    "                #print(\"Params\\nk: %s\\tp: %s\\tt: %f\" % (k, p, t))\n",
    "\n",
    "                #create and score classifier with given hyperparameters\n",
    "                clf = svm.SVC(kernel=k, probability=p, tol=t)\n",
    "                score = score(clf, data, labels)\n",
    "                score = convert_to_FP_FN(labels, score[0], score[1])\n",
    "\n",
    "                # keep track of paretofront\n",
    "                ind = [score, (k,p,t)]\n",
    "                front = update_front(front, ind, pareto_dominance_min)\n",
    "\n",
    "                # document performance\n",
    "                #print(\"FP: %f\\tFN: %f\" % (score[0],score[1]))\n",
    "                #print(\"*********************************************\")\n",
    "\n",
    "\n",
    "        # return pareto front classifiers\n",
    "    return front\n",
    "    # return generate_SVM_front(front)\n",
    "\n",
    "def generate_SVM_front(front):\n",
    "    # implements svms for each point on the pareto front\n",
    "    # returns a list of SVMs\n",
    "    models = []\n",
    "    for ind in front:\n",
    "        clf = svm.SVC(kernel=ind[1][0], probability=ind[1][1], tol=ind[1][2])\n",
    "        models += [clf]\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code will find an optimal pareto front of SVM classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_knn(data, labels):\n",
    "    neighbors = list(range(1,50))\n",
    "    front = []\n",
    "    for k in neighbors:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        scores = score(knn, data, labels)\n",
    "        precision, recall = scores\n",
    "        score = convert_to_FP_FN(labels, precision, recall)\n",
    "        individual = [score, [k]]\n",
    "        front = update_front(front, individual, pareto_dominance_min)\n",
    "    return front\n",
    "    # return generate_KNN_front(front)\n",
    "\n",
    "def generate_KNN_front(front):\n",
    "    # implements svms for each point on the pareto front\n",
    "    # returns a list of SVMs\n",
    "    models = []\n",
    "    for individual in front:\n",
    "        clf = KNeighborsClassifier(n_neighbors = individual[1][0])\n",
    "        models += [clf]\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code will find the optimal pareto front of KNN classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_gaussianNB(data, labels):\n",
    "    front = []\n",
    "    scores = parser.score(GaussianNB(), data, labels)\n",
    "    precision, recall = scores\n",
    "    score = convert_to_FP_FN(labels, precision, recall)\n",
    "    individual = [score, []]\n",
    "    front = update_front(front, individual, pareto_dominance_min)\n",
    "    return front"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code will produce the inly available gaussian bayes net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fp_fn(clf, train, test):\n",
    "    x_train, y_train = train\n",
    "    x_test, y_test = test\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    # predict the response\n",
    "    preds = clf.predict(x_test)\n",
    "    fp = sum([1 for i in range(len(preds)) if preds[i] == 1 and y_test[i][1] == 0])\n",
    "    fn = sum([1 for i in range(len(preds)) if preds[i] == 0 and y_test[i][1] == 1])\n",
    "    return (fp, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above method will return the false positives and false negatives for the given classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can put it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train.csv\n",
      "Loaded test.csv\n",
      "Loaded gender_submission.csv\n"
     ]
    }
   ],
   "source": [
    "train, test = load_split_all()\n",
    "train_x, train_y = train\n",
    "test_x, test_y = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we organize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for best random forest\n"
     ]
    }
   ],
   "source": [
    "rf_front = rfClassifier.find_best_rf(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for best SVM\n"
     ]
    }
   ],
   "source": [
    "svm_front = svm.find_best_SVM(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for best knn\n"
     ]
    }
   ],
   "source": [
    "knn_front = knnClassifier.find_best_knn(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_front = find_best_gaussianNB(train_x, train_y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now we find our pareto fronts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-e27c0f3dcdba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Don't actually use test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrf_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_fp_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrf_front\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msvm_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_fp_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msvm_front\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mknn_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_fp_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mknn_front\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgnb_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_fp_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgnb_front\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-c7fecec3034f>\u001b[0m in \u001b[0;36mget_fp_fn\u001b[0;34m(clf, train, test)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# predict the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train[0], train[1], train_size=.2) # Don't actually use test data\n",
    "rf_scores = np.asarray([get_fp_fn(clf, (x_train, y_train), (x_test, y_test)) for clf in rf_front])\n",
    "svm_scores = np.asarray([get_fp_fn(clf, train, test) for clf in svm_front])\n",
    "knn_scores = np.asarray([get_fp_fn(clf, train, test) for clf in knn_front])\n",
    "gnb_scores = np.asarray([get_fp_fn(clf, train, test) for clf in gnb_front])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to evaluate these clean these front results, as though they formed the pareto-front on our cross-eval'ed training, they are not necessarily all in the pareto-front for our final test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_true = []\n",
    "for score in rf_scores:\n",
    "    score = [score, ()] # dummy\n",
    "    rf_true = update_front(rf_true, score, pareto_dominance_min)\n",
    "rf_scores = np.asarray([np.asarray(ind[0]) for ind in rf_true])\n",
    "svm_true = []\n",
    "for score in svm_scores:\n",
    "    score = [score, ()]\n",
    "    svm_true = update_front(svm_true, score, pareto_dominance_min)\n",
    "svm_scores = np.asarray([np.asarray(ind[0]) for ind in svm_true])\n",
    "knn_true = []\n",
    "for score in knn_scores:\n",
    "    score = [score, ()]\n",
    "    knn_true = update_front(knn_true, score, pareto_dominance_min)\n",
    "knn_scores = np.asarray([np.asarray(ind[0]) for ind in knn_true])\n",
    "\n",
    "# Sort scores so they display pseudo HoF\n",
    "rf_scores = rf_scores[np.argsort(rf_scores[:, 0])]\n",
    "svm_scores = svm_scores[np.argsort(svm_scores[:, 0])]\n",
    "knn_scores = knn_scores[np.argsort(knn_scores[:, 0])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can graph our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"Titanic Pareto Fronts\")\n",
    "ax.plot(rf_scores[:,0], rf_scores[:,1], c='b', marker='o', markersize='12', label='RF')\n",
    "ax.plot(svm_scores[:, 0], svm_scores[:, 1], c='g', marker='o', markersize='12', label='SVM')\n",
    "ax.plot(knn_scores[:, 0], knn_scores[:, 1], c='r', marker='o', markersize='12', label='KNN')\n",
    "ax.plot(gnb_scores[:,0], gnb_scores[:,1], c='m', marker='o', markersize='12', label='GNB')\n",
    "# ax.plot(gnb_scores[:, 0], gnb_scores[:, 1], c='m', label='GNB')\n",
    "plt.xlabel(\"False Positives\")\n",
    "plt.ylabel(\"False Negatives\")\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHOW ME THE GRAPHS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
